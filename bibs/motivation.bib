@article{Pearl2014,
archivePrefix = {arXiv},
arxivId = {arXiv:1503.01603v1},
author = {Pearl, Judea and Bareinboim, Elias and Mar, M E},
doi = {10.1214/14-STS486},
eprint = {arXiv:1503.01603v1},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/1503.01603.pdf:pdf},
keywords = {Experimental design, generalizability, causal effe,and phrases,ap-,causal,effects,experimental design,external validity,generalizability,means that we usually,most studies are conducted,plying the results elsewhere,with the intention of},
number = {4},
pages = {579--595},
title = {{External Validity : From Do-Calculus to Transportability Across Populations}},
volume = {29},
year = {2014}
}
@article{Pearl2018,
author = {Pearl, Judea and Bareinboim, Elias},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/r478.pdf:pdf},
keywords = {external validity,generalizability,selection bias,transportability},
number = {November},
pages = {1--5},
title = {{Commentary: EPIDEMIOLOGY MS{\#} EDE18-0227 A note on "Generalizability of Study Results"}},
volume = {1750807},
year = {2018}
}
@article{Braver2014,
author = {Braver, Sanford L and Thoemmes, Felix J and Rosenthal, Robert},
doi = {10.1177/1745691614529796},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/1745691614529796.pdf:pdf},
keywords = {1 proved their perspicacity,daniel,effect-size heterogeneity,future nobel prize winner,kahneman and amos tversky,meta-analysis,over 40 years ago,replication,statistical intuition},
title = {{Continuously Cumulating Meta-Analysis and Replicability}},
year = {2014}
}
@article{Lesko2018,
author = {Lesko, Catherine R and Buchanan, Ashley L and Westreich, Daniel and Edwards, Jessie K},
doi = {10.1097/EDE.0000000000000664.Generalizing},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/nihms862564.pdf:pdf},
isbn = {0000000000000},
number = {4},
pages = {553--561},
title = {{Generalizing study results: a potential outcomes perspective}},
volume = {28},
year = {2018}
}
@article{Allcott2015,
author = {Allcott, Hunt},
doi = {10.1093/qje/qjv015.Advance},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/qjv015.pdf:pdf},
pages = {1117--1165},
title = {{Site Selection Bias in Program Evaluation}},
year = {2015}
}
@article{Aronow2015,
author = {Aronow, Peter M and Samii, Cyrus},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/SSRN-id2224964.pdf:pdf},
keywords = {causal inference,external validity,multiple regression,observational studies,random-},
title = {{Does Regression Produce Representative Estimates of Causal Effects}},
volume = {06520},
year = {2015}
}
@book{Lehmann1998,
abstract = {This second, much enlarged edition by Lehmann and Casella of Lehmann's classic text on point estimation maintains the outlook and general style of the first edition. All of the topics are updated. An entirely new chapter on Bayesian and hierarchical Bayesian approaches is provided, and there is much new material on simultaneous estimation. Each chapter concludes with a Notes section which contains suggestions for further study. The book is a companion volume to the second edition of Lehmann's "Testing Statistical Hypotheses". E.L. Lehmann is Professor Emeritus at the University of California, Berkeley. He is a member of the National Academy of Sciences and the American Academy of Arts and Sciences, and the recipient of honorary degrees from the University of Leiden, The Netherlands, and the University of Chicago. George Casella is the Liberty Hyde Bailey Professor of Biological Statistics in The College of Agriculture and Life Sciences at Cornell University. Casella has served as associate editor of The American Statistician, Statistical Science and JASA. He is currently the Theory and Methods Editor of JASA. Casella has authored two other textbooks (Statistical Inference, 1990, with Roger Berger and Variance Components, 1992, with Shayle A. Searle and Charles McCulloch). He is a fellow of the IMS and ASA, and an elected fellow of the ISI.Also available:E.L. Lehmann, Testing Statistical Hypotheses Second Edition, Springer-Verlag New York, Inc., ISBN 0-387-949194.},
author = {Lehmann, E L and Casella, G},
booktitle = {Design},
doi = {10.2307/1270597},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/E L Lehaman.pdf:pdf},
isbn = {0387985026},
issn = {00401706},
number = {3},
pages = {589},
pmid = {3087590},
title = {{Theory of Point Estimation , Second Edition Springer Texts in Statistics}},
url = {http://www.amazon.com/dp/0387985026},
volume = {41},
year = {1998}
}
@article{Athey2017,
author = {Athey, Susan and Imbens, Guido W},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/jep.31.2.3.pdf:pdf},
number = {2},
pages = {3--32},
title = {{The State of Applied Econometrics: Causality and Policy Evaluation}},
volume = {31},
year = {2017}
}
@article{Chassang2010,
author = {Chassang, Sylvain and i Miquel, Gerard Padro and Snowberg, Erik},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/w16343.pdf:pdf},
keywords = {To Read},
title = {{Selective Trials and Information Production in Randomized Controlled Experiments}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.163.5979{\&}rep=rep1{\&}type=pdf{\%}5Cnpapers3://publication/uuid/81A54BE7-4ACE-4037-8DB5-66BEF6A134A0},
year = {2010}
}
@article{Pritchett2017,
author = {Pritchett, Lant},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/ed1b75ed0076011aa93f37672d30393834fa.pdf:pdf},
pages = {1--9},
title = {{“The Evidence” About “What Works” in Education: Graphs to Illustrate External Validity and Construct Validity}},
year = {2017}
}
@article{One,
author = {One, P A R T},
file = {:home/nandan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/One - Unknown - Getting Started From “It Worked Th ere” to “It Will Work Here” What's in Th is Book and Why.pdf:pdf},
title = {{Getting Started: From “It Worked Th ere” to “It Will Work Here” What's in Th is Book and Why}}
}
@article{Vivalt2017,
abstract = {Impact evaluations aim to predict the future, but they are rooted in particular contexts and to what extent they generalize is an open and important question. We exploit a new data set of results on a wide variety of interventions and find more heterogeneity than in other literatures. This has implications for how evidence is generated and used to inform policy.},
author = {Vivalt, Eva},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/How-Much-Can-We-Generalize.pdf:pdf},
journal = {Working Paper, Australian National University},
title = {{How Much Can We Generalize from Impact Evaluations ?}},
year = {2017}
}
@article{Peters2018,
abstract = {{\textcopyright} The Author(s) 2018. Published by Oxford University Press on behalf of the International Bank for Reconstruction and Development / THE WORLD BANK. All rights reserved. When properly implemented, Randomized Controlled Trials (RCT) achieve a high degree of internal validity. Yet, if an RCT is to inform policy, it is critical to establish external validity. This paper systematically reviews all RCTs conducted in developing countries and published in leading economic journals between 2009 and 2014 with respect to how they deal with external validity. Following Duflo, Glennerster, and Kremer (2008), we scrutinize the following hazards to external validity: Hawthorne effects, general equilibrium effects, specific sample problems, and special care in treatment provision. Based on a set of objective indicators, we find that the majority of published RCTs does not discuss these hazards and many do not provide the necessary information to assess potential problems. The paper calls for including external validity dimensions in a more systematic reporting on the results of RCTs. Thismay create incentives to avoid overgeneralizing findings and help policymakers to interpret results appropriately.},
author = {Peters, J{\"{o}}rg and Langbein, J{\"{o}}rg and Roberts, Gareth},
doi = {10.1093/wbro/lkx005},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/lkx005.pdf:pdf},
issn = {15646971},
journal = {World Bank Research Observer},
number = {1},
pages = {34--64},
title = {{Generalization in the tropics-development policy, randomized controlled trials, and external validity}},
volume = {33},
year = {2018}
}
@article{Manski2013,
abstract = {Manski argues that public policy is based on untrustworthy analysis. Failing to account for uncertainty in an uncertain world, policy analysis routinely misleads policy makers with expressions of certitude. Manski critiques the status quo and offers an innovation to improve both how policy research is conducted and how it is used by policy makers.},
author = {Manski, Charles F.},
doi = {10.4159/harvard.9780674067547},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/Public-Policy-in-an-Uncertain-World-Analysis-and-Decisions.pdf:pdf},
journal = {Public Policy in an Uncertain World},
title = {{Public Policy in an Uncertain World}},
year = {2013}
}
@article{Snowberg2016,
author = {Banerjee, Abhijit and Chassang, Sylvain and Snowberg, Erik},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/w22167.pdf:pdf},
title = {{Decision Theoretic Approaches to Experiment Desig}},
year = {2016}
}
@article{Deaton2010,
abstract = {There is currently much debate about the effectiveness of foreign aid and about what kind of projects can engender economic development. There is skepticism about the ability of econometric analysis to resolve these issues or of development agencies to learn from their own experience. In response, there is increasing use in development economics of randomized controlled trials (RCTs) to accumulate credible knowledge of what works, without overreliance on questionable theory or statistical methods. When RCTs are not possible, the proponents of these methods advocate quasi- randomization through instrumental variable (IV) techniques or natural experiments. I argue that many of these applications are unlikely to recover quantities that are useful for policy or understanding: two key issues are the misunderstanding of exogeneity and the handling of heterogeneity. I illustrate from the literature on aid and growth. Actual randomization faces similar problems as does quasi-randomization, notwithstanding rhetoric to the contrary. I argue that experiments have no special ability to produce more credible knowledge than other methods, and that actual experiments are frequently subject to practical problems that undermine any claims to statistical or epistemic superiority. I illustrate using prominent experiments in development and elsewhere. As with IV methods, RCT-based evaluation of projects, without guidance from an understanding of underlying mechanisms, is unlikely to lead to scientific progress in the understanding of economic development. I welcome recent trends in development experimentation away from the evaluation of projects and toward the evaluation of theoretical mechanisms. (JEL C21, F35, O19)},
author = {Deaton, Angus},
doi = {10.1257/jel.48.2.424},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/deaton instruments randomization learning about development jel 2010.pdf:pdf},
issn = {0022-0515},
journal = {Journal of Economic Literature},
month = {jun},
number = {2},
pages = {424--455},
title = {{Instruments, Randomization, and Learning about Development}},
url = {http://pubs.aeaweb.org/doi/10.1257/jel.48.2.424},
volume = {48},
year = {2010}
}
@article{Banerjee2016,
abstract = {The objective of this case study was to obtain some first-hand information about the functional consequences of a cosmetic tongue split operation for speech and tongue motility. One male patient who had performed the operation on himself was interviewed and underwent a tongue motility assessment, as well as an ultrasound examination. Tongue motility was mildly reduced as a result of tissue scarring. Speech was rated to be fully intelligible and highly acceptable by 4 raters, although 2 raters noticed slight distortions of the sibilants /s/ and /z/. The 3-dimensional ultrasound demonstrated that the synergy of the 2 sides of the tongue was preserved. A notably deep posterior genioglossus furrow indicated compensation for the reduced length of the tongue blade. It is concluded that the tongue split procedure did not significantly affect the participant's speech intelligibility and tongue motility.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Banerjee, Abhijit and Duflo, Esther and Kremer, Michael},
doi = {10.1007/s13398-014-0173-7.2},
eprint = {arXiv:1011.1669v3},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/the-influence-of-rcts-on-developmental-economics-research-and-development-policy.pdf:pdf},
isbn = {9780874216561},
issn = {0717-6163},
journal = {Working Paper},
pages = {1--76},
pmid = {15003161},
title = {{The Influence of Randomized Controlled Trials on Development Economics Research and on Development Policy}},
url = {http://www.americanbanker.com/issues/179{\_}124/which-city-is-the-next-big-fintech-hub-new-york-stakes-its-claim-1068345-1.html{\%}5Cnhttp://www.ncbi.nlm.nih.gov/pubmed/15003161{\%}5Cnhttp://cid.oxfordjournals.org/lookup/doi/10.1093/cid/cir991{\%}5Cnhttp://www.scielo},
volume = {d},
year = {2016}
}
@article{LantPritchett&JustinSandefur2016,
author = {{Lant Pritchett {\&} Justin Sandefur}},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/aer.p20151016.pdf:pdf},
journal = {AEA Papers and Proceedings},
number = {5},
pages = {6},
title = {{Learning from Experiments when Context Matters†.: at USF Libraries.}},
url = {http://eds.b.ebscohost.com.ezproxy.lib.usf.edu/eds/pdfviewer/pdfviewer?vid=5{\&}sid=aef21225-20b8-458e-842b-e860243ea5f7{\%}40sessionmgr104{\&}hid=104},
volume = {105},
year = {2016}
}
@article{Pritchett2013,
abstract = {In this paper we examine how policymakers and practitioners should interpret the impact evaluation literature when presented with conflicting experimental and non-experimental estimates of the same intervention across varying contexts. We show three things. First, as is well known, non-experimental estimates of a treatment effect comprise a causal treatment effect and a bias term due to endogenous selection into treatment. When non-experimental estimates vary across contexts any claim for external validity of an experimental result must make the assumption that (a) treatment effects are constant across contexts, while (b) selection processes vary across contexts. This assumption is rarely stated or defended in systematic reviews of evidence. Second, as an illustration of these issues, we examine two thoroughly researched literatures in the economics of education — class size effects and gains from private schooling — which provide experimental and non-experimental estimates of causal effects from the same context and across multiple contexts.  We show that the range of “true” causal effects in these literatures implies OLS estimates from the right context are, at present, a better guide to policy than experimental estimates from a different context. Third, we show that in important cases in economics, parameter heterogeneity is driven by economy- or institution-wide contextual factors, rather than personal characteristics, making it difficult to overcome external validity concerns through estimation of heterogeneous treatment effects within a single localized sample. We conclude with recommendations for research and policy, including the need to evaluate programs in context, and avoid simple analogies to clinical medicine in which “systematic reviews” attempt to identify best-practices by putting most (or all) weight on the most “rigorous” evidence with no allowance for context.},
author = {Pritchett, Lant and Sandefur, Justin},
doi = {10.2139/ssrn.2364580},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/context-matters-for-size{\_}1.pdf:pdf},
journal = {SSRN Electronic Journal},
keywords = {causal inference,external validity,policy evaluation,treatment effects},
number = {August 2013},
title = {{Context Matters for Size: Why External Validity Claims and Development Practice Don't Mix}},
year = {2013}
}
@article{Meager2018,
author = {Meager, Rachael},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/Meager-Distributional-Effects-Aggregation-November-2018-external-appendices.pdf:pdf},
title = {{Aggregating Distributional Treatment Effects : A Bayesian Hierarchical Analysis of the Microcredit Literature}},
year = {2018}
}
@article{Deaton2018,
author = {Deaton, Angus and Cartwright, Nancy},
doi = {10.1016/j.socscimed.2017.12.005},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/1-s2.0-S0277953617307359-main.pdf:pdf},
issn = {0277-9536},
journal = {Social Science {\&} Medicine},
keywords = {Balance,Bias,Economic development,External validity,Health,Precision,RCTs,Transportation of results},
number = {October 2017},
pages = {2--21},
publisher = {Elsevier},
title = {{Understanding and misunderstanding randomized controlled trials}},
url = {https://doi.org/10.1016/j.socscimed.2017.12.005},
volume = {210},
year = {2018}
}
@book{Shadish2002,
author = {Shadish, William R and Cook, Thomas D and Campbell, Donald T.},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/Experimental-and-Quasi-Experimental-Designs-for-Generalized-Causal-Inference.pdf:pdf},
isbn = {0395615569},
title = {{Experimental and Designs for Generalized Causal Inference}},
year = {2002}
}
@book{Cartwright,
author = {Cartwright, Nancy and Hardie, Jeremy},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/Evidence-Based-Policy-A-Practical-Guide-to-Doing-It-Better.pdf:pdf},
isbn = {9780199841622},
title = {{Evidence-Based Policy}}
}
@article{Imbens2014,
author = {Imbens, Guido},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/3648.pdf:pdf},
pages = {1--8},
title = {{COMMENTS ON: “UNDERSTANDING AND MISUNDERSTANDING RANDOMIZED CONTROLLED TRIALS” BY CARTWRIGHT AND DEATON GUIDO}},
year = {2014}
}
@article{Gechter2015,
author = {Gechter, Michael},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/Gechter{\_}Generalizing{\_}Social{\_}Experiments.pdf:pdf},
number = {2008},
pages = {1--50},
title = {{Generalizing the Results from Social Experiments : Theory and Evidence from Mexico and India }},
year = {2015}
}
@article{Rosenzweig2019,
author = {Rosenzweig, Mark R. and Udry, Christopher},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/SSRN-id3392657.pdf:pdf},
title = {{External Validity in a Stochastic World: Evidence from Low-Income Countries}},
year = {2019}
}
@article{Bisbee2017,
abstract = {We investigate whether local average treatment effects (LATE's) can be extrapolated to new settings. We extend the analysis and framework of Dehejia, Pop-Eleches, and Samii (2015), which examines the external validity of the Angrist-Evans (1998) reduced-form natural experiment of having two first children of the same sex on the probability of an incremental child and on mother's labor supply. We estimate Angrist and Evans's (1998) same-sex instrumental variable strategy in 139 country-year censuses using data from the Integrated Public Use Micro Sample International. We compare each country-year's LATE, as a hypothetical target, to the LATE extrapolated from other country-years (using the approach suggested by Angrist and Fernandez-Val 2010). Paralleling our findings in Dehejia, Pop-Eleches, and Samii (2015), we find that with a sufficiently large reference sample, we extrapolate the treatment effect reasonably well, but the degree of accuracy depends on the extent of covariate similarity between the target and reference settings. Our results suggest that – at least for our application – there is hope for external validity.},
author = {Bisbee, James and Dehejia, Rajeev and Pop-Eleches, Cristian and Samii, Cyrus},
doi = {10.1086/691280},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/691280.pdf:pdf},
issn = {0734-306X},
journal = {Journal of Labor Economics},
number = {S1},
pages = {S99--S147},
title = {{Local Instruments, Global Extrapolation: External Validity of the Labor Supply–Fertility Local Average Treatment Effect}},
volume = {35},
year = {2017}
}
