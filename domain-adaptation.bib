@article{Jan,
archivePrefix = {arXiv},
arxivId = {arXiv:1812.11806v2},
author = {Jan, L G},
eprint = {arXiv:1812.11806v2},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/1812.11806.pdf:pdf},
keywords = {covariate shift,domain adapta-,machine learning,pattern recognition,sample selection bias,tion,transfer learning},
title = {domain adaptation and transfer learning}
}
@article{Pinheiro,
author = {Pinheiro, Pedro O},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/Pinheiro{\_}Unsupervised{\_}Domain{\_}Adaptation{\_}CVPR{\_}2018{\_}paper.pdf:pdf},
number = {i},
title = {{Unsupervised Domain Adaptation with Similarity Learning}}
}
@article{DaumeIII2010,
abstract = {We describe an approach to domain adapta-tion that is appropriate exactly in the case when one has enough " target " data to do slightly better than just using only " source " data. Our approach is incredibly simple, easy to implement as a preprocessing step (10 lines of Perl!) and outperforms state-of-the-art approaches on a range of datasets. Moreover, it is trivially extended to a multi-domain adaptation problem, where one has data from a variety of different domains.},
author = {{Daum{\'{e}} III}, Hal},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/39d9d019c7c7974c264567b35ab7849e5cc4.pdf:pdf},
journal = {ACL Workshop on Domain Adaptation for NLPomain Adaptation for NLP},
number = {July},
pages = {53----59},
title = {{Frustratingly Easy Semi-Supervised Domain Adaptation}},
year = {2010}
}
@article{Suigyama2007,
abstract = {A situation where training and test samples follow different input distributions is called covariate shift. Under covariate shift, standard learning methods such as maximum likelihood estimation are no longer consistent—weighted variants ac- cording to the ratio of test and training input densities are consistent. Therefore, accurately estimating the density ratio, called the importance, is one of the key is- sues in covariate shift adaptation. A naive approach to this task is to first estimate training and test input densities separately and then estimate the importance by taking the ratio of the estimated densities. However, this naive approach tends to perform poorly since density estimation is a hard task particularly in high dimen- sional cases. In this paper, we propose a direct importance estimation method that does not involve density estimation. Our method is equipped with a natural cross validation procedure and hence tuning parameters such as the kernel width can be objectively optimized. Simulations illustrate the usefulness of our approach.},
author = {Suigyama, Masashi and Nakajima, Shinichi and Kashima, Hisashi and Buenau, Paul and Kawanabe, Motoaki and Sugiyama, Masashi and Nakajima, Shinichi and Kashima, Hisashi and {Von B{\"{u}}nau}, Paul and Kawanabe, Motoaki},
doi = {10.1007/s10463-008-0197-x},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/3248-direct-importance-estimation-with-model-selection-and-its-application-to-covariate-shift-adaptation.pdf:pdf},
isbn = {160560352X},
issn = {00203157},
journal = {Proceedings of the 20th International Conference on Neural Information Processing Systems},
keywords = {Theory {\&} Algorithms},
pages = {1433--1440},
title = {{Direct Importance Estimation with Model Selection and Its Application to Covariate Shift Adaptation}},
url = {http://eprints.pascal-network.org/archive/00003287/},
year = {2007}
}
@article{Shimodaira2000,
abstract = {A class of predictive densities is derived by weighting the observed samples in maximizing the log-likelihood function. This approach is eeective in cases such as sample surveys or design of experiments, where the observed covariate follows a diierent distribution than that in the whole population. Under misspeci{\"{y}}cation of the parametric model, the optimal choice of the weight function is asymptotically shown to be the ratio of the density function of the covariate in the population to that in the observations. This is the pseudo-maximum likelihood estima-tion of sample surveys. The optimality is de{\"{y}}ned by the expected Kullback–Leibler loss, and the optimal weight is obtained by considering the importance sampling identity. Under correct speci{\"{y}}cation of the model, however, the ordinary maximum likelihood estimate (i.e. the uniform weight) is shown to be optimal asymptotically. For moderate sample size, the situation is in between the two extreme cases, and the weight function is selected by minimizing a variant of the information criterion derived as an estimate of the expected loss. The method is also applied to a weighted version of the Bayesian predictive density. Numerical examples as well as Monte-Carlo simulations are shown for polynomial regression. A connection with the robust parametric estimation is discussed.},
author = {Shimodaira, Hidetoshi},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/1-s2.0-S0378375800001154-main.pdf:pdf},
journal = {Journal of Statistical Planning and Inference},
keywords = {62B10,62D05 Keywords,Akaike information criterion,Design of experiments,Importance sampling,Kullback–Leibler divergence,MSC,Misspeci{\"{y}}cation,Sample surveys,Weighted least squares},
pages = {227--244},
title = {{Improving predictive inference under covariate shift by weighting the log-likelihood function}},
url = {www.elsevier.com/locate/jspi},
volume = {90},
year = {2000}
}
@article{Pan2010,
abstract = {{\textcopyright} Springer International Publishing AG, part of Springer Nature 2018. Recommending tweets that a user might retweet plays an important role either in satisfying users' information needs or in the dissemination of information in microblogging services such as Twitter. In this paper, we propose a deep neural network for tweet recommendations with author-based Long Short-Term Memory networks for learning the latent representations/embeddings of tweets. Our approach predicts the preference score of a tweet based on (1) the similarity between the embeddings of a user and the tweet, (2) the similarity between the embeddings of the user and the author (who posted the tweet). Despite its simplicity, we present that our approach can significantly outperform state-of-the-art methods with or without explicit features for recommending tweets in terms of five evaluation metrics.},
archivePrefix = {arXiv},
arxivId = {1603.06111},
author = {Pan, Sinno Jialin and Yang, Qiang},
doi = {10.1109/TKDE.2009.191},
eprint = {1603.06111},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/tkde{\_}transfer{\_}learning.pdf:pdf},
isbn = {9791095546009},
issn = {1041-4347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Ambiguity,Automated essay scoring,Automated essay scoring (AES),Automated scoring system,Automatic reference answer generation,Class imbalance,Convolutional neural networks,Data mining,Deep learning,Deep neural network,Domain adaptation,Emotion Classification,Essay,Finite state automata,Generalized Latent Semantic Analysis,Hierarchical Recurrent Neural Networks,Image classification,Imbalanced training,Latent Semantic Analysis,Levenshtein distance,Long short-term memory,Machine learning,Maximum marginal relevance,N-gram,Natural Language Processing,Neural network,Oversampling,Penilaian Otomatis,Rating criteria,Semantic word representations,Sentence similarity,Sentiment Classification,Short answer scoring,Singular Value Decomposition,Spelling correction,Survey,Technical Papers: Machine Learning Methods,Technical Papers: Natural Language Processing and,Topic information,Transfer learning,and engineering,and identify the substances,asap dataset,assessment mecha- did you,attention layer,automatic scoring,background information about mr,bi-lstm,char embedding,clustering,computer-assisted language learning,deep learning,ding,during the story,effect that background information,ek laboratories,essay exams,evolutionary,explain the,fault diagnosis,finite state automata,fully connected layer,glove,has on paul,how,icle,in mock rocks,keyword,learning to rank,leonard,levenshtein distance,long short-term memory,lstm,n-gram,nanyang technological university,prompt,question,recurrent neural network,remaining useful life,school of computer science,semantic similarity,semantics similarity,sentence similarity,separate the salt from,short answers are powerful,short-answer scoring,siamese neural network,singapore,spelling,support,swam intelligence,text mining,text similarity,the reader gets,the water,to separate,transfer learning,word embed-,you used several methods},
month = {oct},
number = {10},
pages = {1345--1359},
pmid = {24086296},
title = {{A Survey on Transfer Learning}},
url = {https://doi.org/10.1016/j.artmed.2018.03.006{\%}0Ahttp://arxiv.org/abs/1801.06146{\%}0Ahttp://arxiv.org/abs/1902.01382{\%}0Ahttp://arxiv.org/abs/1902.09092{\%}0Ahttp://arxiv.org/abs/1703.06345{\%}0Ahttp://dblp.org/rec/conf/aaai/ZhouPTH16{\%}0Awww.aaai.org{\%}0Ahttp://arxiv.or http://ieeexplore.ieee.org/document/5288526/},
volume = {22},
year = {2010}
}
@article{Ben-David2006,
author = {Ben-David, Shai and Blitzer, John and Crammer, Koby and Pereira, Fernando},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/nips06.pdf:pdf},
title = {{Analysis of Representations for Domain Adaptation}},
year = {2006}
}
@article{John2010,
author = {John, Shai Ben-david and Koby, Blitzer and Kulesza, Alex and Pereira, Fernando and Vaughan, Jennifer Wortman},
doi = {10.1007/s10994-009-5152-4},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/36364.pdf:pdf},
pages = {151--175},
title = {{A theory of learning from different domains}},
year = {2010}
}
@book{Weiss2016,
abstract = {Machine learning and data mining techniques have been used in numerous real-world applications. An assumption of traditional machine learning methodologies is the training data and testing data are taken from the same domain, such that the input feature space and data distribution characteristics are the same. However, in some real-world machine learning scenarios, this assumption does not hold. There are cases where training data is expensive or difficult to collect. Therefore, there is a need to create high-performance learners trained with more easily obtained data from different domains. This methodology is referred to as transfer learning. This survey paper formally defines transfer learning, presents information on current solutions, and reviews applications applied to transfer learning. Lastly, there is information listed on software downloads for various transfer learning solutions and a discussion of possible future research work. The transfer learning solutions surveyed are independent of data size and can be applied to big data environments.},
author = {Weiss, Karl and Khoshgoftaar, Taghi M. and Wang, Ding Ding},
booktitle = {Journal of Big Data},
doi = {10.1186/s40537-016-0043-6},
file = {:home/nandan/Dropbox/Research/Random Papers to Read/10.1186{\_}s40537-016-0043-6.pdf:pdf},
isbn = {4053701600},
issn = {21961115},
keywords = {Data mining,Domain adaptation,Machine learning,Survey,Transfer learning},
number = {1},
publisher = {Springer International Publishing},
title = {{A survey of transfer learning}},
volume = {3},
year = {2016}
}
